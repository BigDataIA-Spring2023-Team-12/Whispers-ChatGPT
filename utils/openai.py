import os
import openai
from decouple import config


def transcribe_audio(file_path: str, model: str) -> str:
    """
    Transcribes an audio file using the OpenAI API.

    Args:
        file_path (str): The path to the audio file.
        model (str): The name of the OpenAI model to use for transcription.

    Returns:
        str: The transcription of the audio file.

    """
    openai.api_key = config("OPENAI_API_KEY")
    audio_file = open(file_path, "rb")
    transcript = openai.Audio.transcribe(model, audio_file)
    return transcript["text"]


def generate_text(prompt):
    """
    Generates text using the OpenAI ChatCompletion API based on the given prompt.

    Args:
    - prompt (str): The prompt to use for the OpenAI ChatCompletion API.

    Returns:
    - response (str): The response generated by the OpenAI ChatCompletion API.
    """
    openai.api_key = config("OPENAI_API_KEY")

    completion = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "user", "content": f"{prompt}"}
        ]
    )

    response = completion.choices[0].message["content"]
    return response


def string_to_txt(response, filename):
    # string to txt file
    with open(f"processed/{filename}.txt", "w") as text_file:
        text_file.write(response)
    return f"processed/{filename}.txt"


def create_prompt(response):
    questions = {
        1: "What was the main purpose or objective of the meeting?",
        2: "Were all the agenda items discussed and resolved?",
        3: "Was there any conflict or disagreement among the members during the meeting?"
        # 4 : "Were there any significant changes or decisions made during the meeting that will impact the organization or community?",
        # 5 : "Was everyone given the opportunity to participate and voice their opinions or concerns during the meeting?"
    }
    context = "\n Based on above answer the following questions less than 100 words:\n"

    for i, q in questions.items():
        context = context + f"{i}. {q}\n"

    prompt = response + context

    return prompt
